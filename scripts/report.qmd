---
title: "Huang, Cards 2024"
# format: 
#   docx:
#     reference-doc: "./custom-reference-doc.docx"

format:
  html:
    embed-resources: true
    toc: true

execute: 
  echo: false
---

```{python}
from redcap import Project
from great_tables import GT, md, html
from statsmodels.stats.weightstats import ttest_ind
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sys
```

```{python}
# Import project-specific functions
# Set the path to the custom functions directory
sys.path.append("../functions")

from functions import get_api_key
from functions import freq_prop
from functions import test
from functions import pre_post_tab
from functions import plot
```

```{python}
# Get pre data
# Project_id = 26779
api_url = 'https://redcap.ucdenver.edu/api/'
api_key = get_api_key(26779)
project = Project(api_url, api_key)
pre = project.export_records()
pre = pd.DataFrame.from_dict(pre)
pre["timepoint"] = "pre"
```

```{python}
# Get post data
# Project_id = 26791
api_url = 'https://redcap.ucdenver.edu/api/'
api_key = get_api_key(26791)
project = Project(api_url, api_key)
post = project.export_records()
post = pd.DataFrame.from_dict(post)
post["timepoint"] = "post"
```

## Ethnicity
```{python}
# Recode numeric values to categorical
pre['Ethnicity'] = pre['ethnicity'].replace({
    '1':	'American Indian / Alaskan Native',
    '2':	'Asian',
    '3':	'Black or African American',
    '4':	'Hispanic, Latinx or Spanish',
    '5':	'Middle Eastern / Northern African',
    '6':	'Pacific islander / Native Hawaiian',
    '7':	'White',
    '8':	'Prefer not to answer',
    '9':	'Other'})

# Create the basic table
freq_prop(pre, "Ethnicity")
```

## Role
```{python}
pre['Role'] = pre['role'].replace({
    '1':	'Student',
    '2':	'Resident',
    '3':	'Attending Physician',
    '4':	'Advanced Practice Provider',
    '5':	'Clinical Staff',
    '6':	'Other'})

# Create the basic table
freq_prop(pre, "Role")
```

## Gender
Categories with fewer than 5 responses were collapased into "Prefer not to answer/Other" to preserve anonymity.
```{python}
pre['Gender'] = pre['gender'].replace({
    '1':	'Female',
    '2':	'Male',
    '3':	'Prefer not to answer/Other',
    '4':	'Prefer not to answer/Other',
    '5':	'Prefer not to answer/Other',
    '6':	'Prefer not to answer/Other',
    '7':    'Prefer not to answer/Other'})

# Create the basic table
freq_prop(pre, "Gender")
```

# Analyses
```{python}
#| eval: true
# Prepare a data frame for q1 and q2 
df = pd.concat(
    [pd.concat([
        pre[["timepoint", "witness_microaggression"]].rename(columns = {"witness_microaggression": "q1"}),
        post[["timepoint", "confident_intervene"]].rename(columns = {"confident_intervene": "q1"})]),
    pd.concat([
        pre[["likely_to_witness"]].rename(columns = {"likely_to_witness": "q2"}),
        post[["likely_intervene"]].rename(columns = {"likely_intervene": "q2"})])],
    axis = 1
)

# For q1
dict = {'1': 'Not at all confident',
    '2': 'Slightly confident',
    '3': 'Moderately confident',
    '4': 'Very confident',
    '': None}

df["q1"] = df["q1"].replace(dict)

# For q2
dict = {'1': 'Not at all likely',
    '2': 'Slightly likely',
    '3': 'Moderately likely',
    '4': 'Very likely',
    '': None}

df["q2"] = df["q2"].replace(dict)

df = df.melt(id_vars = "timepoint",
        value_vars = ["q1", "q2"],
        var_name = "question",
        value_name = "response"
        )

# Drop any missing values
df = df.dropna()

# Set a categorical
df["timepoint"] = pd.Categorical(df.timepoint,
    categories = ["pre", "post"],
    ordered = True)

df["response"] = pd.Categorical(
    df.response,
    categories = ['Not at all likely',
                  'Slightly likely',
                  'Moderately likely',
                  'Very likely',
                  'Not at all confident',
                  'Slightly confident',
                  'Moderately confident',
                  'Very confident'],
    ordered = True)
```



## Confidence in ability to intervene
- Pre: How confident are you in your ability to intervene when witnessing microaggressions or bias?
- Post: After completing the Cards for Humanity activity, how confident are you in your ability to intervene when witnessing microaggressions or bias?
```{python}
#| eval: false
pre_post_tab('q1')
```

```{python}
# Display the scoring system
GT(pd.DataFrame({"Value": [1, 2, 3, 4],
              "Response": ["Not at all confident",
                           "Slightly confident",
                           "Moderately confident",
                           "Very confident"]})
            .set_index("Value")
            .reset_index()
)
```

```{python}
test("witness_microaggression", 
     "confident_intervene",
     "Confidence in ability to intervene")
```

```{python}
plot("witness_microaggression", "confident_intervene")
```

## Likeliness of intervening
- Pre: How likely are you to intervene when you witness microaggressions or bias?
- Post: After completing the Cards for Humanity activity, how likely are you to intervene when you witness microaggressions or bias?
```{python}
#| eval: false
pre_post_tab('q2')
```

```{python}
# Display the response key
GT(pd.DataFrame({"Value": [1, 2, 3, 4],
              "Response": ["Not at all likele",
                           "Slightly likely",
                           "Moderately likely",
                           "Very likely"]})
            .set_index("Value")
            .reset_index()
)
```

```{python}
# table 
test("likely_to_witness", 
     "likely_intervene", 
     "How likely to intervene")
```

```{python}
plot("likely_to_witness", "likely_intervene")
```

## Effectiveness of cards activity
How effective was the Cards for Humanity activity in giving you tools to become an upstander?

```{python}
dict = {'1': 'Not at all effective',
    '2': 'Slightly effective',
    '3': 'Moderately effective',
    '4': 'Very effective',
    '': None}

post['Response'] = post['effective_post'].replace(dict)

# Create the basic table
freq_prop(post, "Response")
```

```{python}
#| eval: false
# Display a table of the available responses
GT(pd.DataFrame({"Value": [1, 2, 3, 4],
              "Response": ["Not at all effective",
                           "Slightly effective",
                           "Moderately effective",
                           "Very effective"]})
            .set_index("Value")
            .reset_index()
)
```

```{python}
#| eval: false
# Display a table with the N, mean, and std
summary = pd.DataFrame(
    {
        "N":       [post["effective_post"].astype(int).count()],
        "Mean":    [post["effective_post"].astype(int).mean().round(2)],
        "Std":     [post["effective_post"].astype(int).std().round(2)]
    }
)

blank_index=[''] * len(summary)
summary.index=blank_index
summary
```

```{python}
# Clean up some of the free text responses
post['Free_text_responses'] = post['commitment'].replace({'n/a':    [None],
              'N/a':    [None],
              '     ':  [None],
              'Abdhdg': [None],
              '':       [None],
              'NA':     [None],
              'None':   [None],
              'N/A':    [None],
              'No':     [None],
              'no':     [None],
              'Na':     [None],
              '.':      [None],
              'none':   [None],
              'NA ':    [None],
              '. ':     [None],
              "-":      [None],
              ' ':      [None],
              ', ':     [None]
              })
              
 
# Print free responses to a .csv file
(pd.DataFrame(post['Free_text_responses']
.unique())
.to_csv("../data/free_text_responses.csv", index = False)
)
```

```{python}
#| eval: false
# Chi square test
# Pre vs post
from scipy.stats import chi2_contingency

dict = {'1': 'Not at all likely',
    '2': 'Slightly likely',
    '3': 'Moderately likely',
    '4': 'Very likely',
    '': None}

pre["Q1_pre"] = pre["likely_to_witness"].replace(dict)

post["Q1_post"] = post["likely_intervene"].replace(dict)

data = [[pre["Q1_pre"].dropna().value_counts().sort_index().to_numpy()],
        [post["Q1_post"].dropna().value_counts().sort_index().to_numpy()]]

data = [[90, 15, 99, 13], [112, 2, 20, 60]]

# The values in data can be a list or an array
# output the test stat, p, dof, expected
stat, p, dof, expected = chi2_contingency(data)
```